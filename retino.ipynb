{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruve/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib\n",
    "from subprocess import check_output\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def classes_to_int(label):\n",
    "    # label = classes.index(dir)\n",
    "    label = label.strip()\n",
    "    if label == \"No DR\":  return 0\n",
    "    if label == \"Mild\":  return 1\n",
    "    if label == \"Moderate\":  return 2\n",
    "    if label == \"Severe\":  return 3\n",
    "    if label == \"Proliferative DR\":  return 4\n",
    "    print(\"Invalid Label\", label)\n",
    "    return 5\n",
    "\n",
    "def int_to_classes(i):\n",
    "    if i == 0: return \"No DR\"\n",
    "    elif i == 1: return \"Mild\"\n",
    "    elif i == 2: return \"Moderate\"\n",
    "    elif i == 3: return \"Severe\"\n",
    "    elif i == 4: return \"Proliferative DR\"\n",
    "    print(\"Invalid class \", i)\n",
    "    return \"Invalid Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "# we need images of same size so we convert them into the size\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "DEPTH = 3\n",
    "inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "# initialize number of epochs to train for, initial learning rate and batch size\n",
    "EPOCHS = 15\n",
    "INIT_LR = 1e-3\n",
    "BS = 12\n",
    "#global variables\n",
    "ImageNameDataHash = {}\n",
    "uniquePatientIDList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrainData(trainDir):\n",
    "    global ImageNameDataHash\n",
    "    # loop over the input images\n",
    "    images = os.listdir(trainDir)\n",
    "    print(\"Number of files in \" + trainDir + \" is \" + str(len(images)))\n",
    "    for imageFileName in images:\n",
    "        if (imageFileName == \"trainLabels.csv\"):\n",
    "            continue\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        imageFullPath = os.path.join(os.path.sep, trainDir, imageFileName)\n",
    "        #print(imageFullPath)\n",
    "        img = load_img(imageFullPath)\n",
    "        arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n",
    "        dim1 = arr.shape[0]\n",
    "        dim2 = arr.shape[1]\n",
    "        dim3 = arr.shape[2]\n",
    "        if (dim1 < HEIGHT or dim2 < WIDTH or dim3 < DEPTH):\n",
    "            print(\"Error image dimensions are less than expected \"+str(arr.shape))\n",
    "        arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n",
    "        #print(arr.shape) # 128,128,3\n",
    "        dim1 = arr.shape[0]\n",
    "        dim2 = arr.shape[1]\n",
    "        dim3 = arr.shape[2]\n",
    "        if (dim1 != HEIGHT or dim2 != WIDTH or dim3 != DEPTH):\n",
    "            print(\"Error after resize, image dimensions are not equal to expected \"+str(arr.shape))\n",
    "        #print(type(arr))\n",
    "        # scale the raw pixel intensities to the range [0, 1] - TBD TEST\n",
    "        arr = np.array(arr, dtype=\"float\") / 255.0\n",
    "        imageFileName = imageFileName.replace('.jpeg','')\n",
    "        ImageNameDataHash[str(imageFileName)] = np.array(arr) \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images at...2019-03-21 09:28:39.756461\n",
      "Number of files in /home/aruve/train is 300\n",
      "Loaded 300 images at...2019-03-21 09:29:29.839369\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Loading images at...\"+ str(datetime.now()))\n",
    "sys.stdout.flush()\n",
    "readTrainData(\"/home/aruve/train\")\n",
    "print(\"Loaded \" + str(len(ImageNameDataHash)) + \" images at...\"+ str(datetime.now())) # 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def readTrainCsv():\n",
    "    raw_df = pd.read_csv('trainLabels.csv', sep=',')\n",
    "    print(type(raw_df)) #<class 'pandas.core.frame.DataFrame'>\n",
    "    row_count=raw_df.shape[0] #gives number of row count row_count=35126 \n",
    "    col_count=raw_df.shape[1] #gives number of col count col count=2\n",
    "    print(\"row_count=\"+str(row_count)+\" col count=\"+str(col_count))\n",
    "    raw_df[\"PatientID\"] = ''\n",
    "    header_list = list(raw_df.columns)\n",
    "    print(header_list) # ['image', 'level', 'PatientID']\n",
    "    # double check if level of left and right are same or not\n",
    "    ImageLevelHash = {}\n",
    "    patientIDList = []\n",
    "    for index, row in raw_df.iterrows():\n",
    "        # 0 is image, 1 is level, 2 is PatientID, 3 is data\n",
    "        key = row[0] + ''\n",
    "        patientID = row[0] + ''\n",
    "        patientID = patientID.replace('_right','')\n",
    "        patientID = patientID.replace('_left','')\n",
    "        #print(\"Adding patient ID\"+ patientID)\n",
    "        raw_df.at[index, 'PatientID'] = patientID\n",
    "        patientIDList.append(patientID)\n",
    "        ImageLevelHash[key] = str(row[1]) # level\n",
    "                \n",
    "    global uniquePatientIDList\n",
    "    uniquePatientIDList = sorted(set(patientIDList))\n",
    "    count=0;\n",
    "    for patientID in uniquePatientIDList:\n",
    "        left_level = ImageLevelHash[str(patientID+'_left')]\n",
    "        right_level = ImageLevelHash[str(patientID+'_right')]\n",
    "        #right_exists = str(patientID+'_right') in raw_df.values\n",
    "        if (left_level != right_level):\n",
    "            count = count+1\n",
    "            #print(\"Warning for patient=\"+ str(patientID) + \" left_level=\" + left_level+ \" right_level=\" +right_level)\n",
    "    print(\"count of images with both left and right eye level not matching=\"+str(count)) # 2240\n",
    "    print(\"number of unique patients=\"+str(len(uniquePatientIDList))) # 17563\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading trainLabels.csv...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "row_count=300 col count=2\n",
      "['image', 'level', 'PatientID']\n",
      "count of images with both left and right eye level not matching=18\n",
      "number of unique patients=150\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "print(\"Reading trainLabels.csv...\")\n",
    "df = readTrainCsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 patient's patientID=10\n",
      "1 patient's patientID=10\n",
      "2 patient's patientID=13\n",
      "3 patient's patientID=13\n",
      "4 patient's patientID=15\n",
      "5 patient's patientID=15\n",
      "6 patient's patientID=16\n",
      "7 patient's patientID=16\n",
      "8 patient's patientID=17\n",
      "9 patient's patientID=17\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    s = df.loc[df.index[i], 'PatientID'] # get patient id of patients\n",
    "    print(str(i) + \" patient's patientID=\"+str(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# df has 3 columns ['image', 'level', 'PatientID']\n",
    "keepImages =  list(ImageNameDataHash.keys())\n",
    "df = df[df['image'].isin(keepImages)]\n",
    "print(len(df)) # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'data']\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "#convert hash to dataframe\n",
    "imageNameArr = []\n",
    "dataArr = []\n",
    "for index, row in df.iterrows():\n",
    "    key = str(row[0])\n",
    "    if key in ImageNameDataHash:\n",
    "        imageNameArr.append(key)\n",
    "        dataArr.append(np.array(ImageNameDataHash[key])) # np.array\n",
    "\n",
    "df2 = pd.DataFrame({'image': imageNameArr, 'data': dataArr})\n",
    "df2_header_list = list(df2.columns) \n",
    "print(df2_header_list) # ['image', 'data']\n",
    "print(len(df2)) # 1000\n",
    "#print(df2.describe(include='all'))\n",
    "#print(df2.sample(3)) # 3 rows x 2 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image    object\n",
      "data     object\n",
      "dtype: object\n",
      "image        object\n",
      "level         int64\n",
      "PatientID    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "if len(df) != len(df2):\n",
    "    print(\"Error length of df != df2\")\n",
    "    \n",
    "for idx in range(0,len(df)):\n",
    "    if (df.loc[df.index[idx], 'image'] != df2.loc[df2.index[idx], 'image']):\n",
    "        print(\"Error \" + df.loc[df.index[idx], 'image'] +\"==\" + df2.loc[df2.index[idx], 'image'])\n",
    "        \n",
    "print(df2.dtypes)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'data', 'level', 'PatientID']\n",
      "300\n",
      "        image                                               data  level  \\\n",
      "254  299_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "\n",
      "    PatientID  \n",
      "254       299  \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df2, df, left_on='image', right_on='image', how='outer')\n",
    "df_header_list = list(df.columns) \n",
    "print(df_header_list) # 'image', 'data', level', 'PatientID'\n",
    "print(len(df)) # 1000\n",
    "print(df.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>data</th>\n",
       "      <th>level</th>\n",
       "      <th>PatientID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image                                               data  level  \\\n",
       "0   10_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
       "1  10_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
       "2   13_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
       "3  13_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
       "4   15_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      1   \n",
       "\n",
       "  PatientID  \n",
       "0        10  \n",
       "1        10  \n",
       "2        13  \n",
       "3        13  \n",
       "4        15  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 128, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image\n"
     ]
    }
   ],
   "source": [
    "sample0 = df.loc[df.index[0], 'data']\n",
    "print(sample0)\n",
    "print(type(sample0)) # <class 'numpy.ndarray'>\n",
    "print(sample0.shape) # 128,128,3\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(sample0, interpolation='nearest')\n",
    "plt.show()\n",
    "print(\"Sample Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['data']\n",
    "Y = df['level']\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "#print(type(X)) # 'pandas.core.series.Series'\n",
    "#X = np.array(X, dtype=\"float\") / 255.0 -- TBD moved to top\n",
    "Y = np.array(Y)\n",
    "# convert the labels from integers to vectors\n",
    "Y =  to_categorical(Y, num_classes=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parttition data into 75:25...\n",
      "Unique patients in dataframe df=150\n",
      "unique_ids shape=150\n",
      "trainid_list shape= 127\n"
     ]
    }
   ],
   "source": [
    "# partition the data into training and testing splits using 75% training and 25% for validation\n",
    "print(\"Parttition data into 75:25...\")\n",
    "sys.stdout.flush()\n",
    "print(\"Unique patients in dataframe df=\" + str(df.PatientID.nunique())) # 500\n",
    "unique_ids = df.PatientID.unique()\n",
    "print('unique_ids shape='+ str(len(unique_ids))) #500\n",
    "\n",
    "# Refer https://www.kaggle.com/kmader/tf-data-tutorial-with-retina-and-keras\n",
    "train_ids, valid_ids = train_test_split(unique_ids, test_size = 0.15, random_state = 10) #stratify = rr_df['level'])\n",
    "trainid_list = train_ids.tolist()\n",
    "print('trainid_list shape=', str(len(trainid_list))) # 375\n",
    "\n",
    "traindf = df[df.PatientID.isin(trainid_list)]\n",
    "valSet = df[~df.PatientID.isin(trainid_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image                                               data  level  \\\n",
      "0   10_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "1  10_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "4   15_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      1   \n",
      "5  15_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      2   \n",
      "6   16_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      4   \n",
      "\n",
      "  PatientID  \n",
      "0        10  \n",
      "1        10  \n",
      "4        15  \n",
      "5        15  \n",
      "6        16  \n",
      "       image                                               data  level  \\\n",
      "2    13_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "3   13_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "20   25_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "21  25_right  [[[0.00392156862745098, 0.00392156862745098, 0...      0   \n",
      "38   47_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "\n",
      "   PatientID  \n",
      "2         13  \n",
      "3         13  \n",
      "20        25  \n",
      "21        25  \n",
      "38        47  \n",
      "      image                                               data  level  \\\n",
      "0   10_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "1  10_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "2   15_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      1   \n",
      "3  15_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      2   \n",
      "4   16_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      4   \n",
      "\n",
      "  PatientID  \n",
      "0        10  \n",
      "1        10  \n",
      "2        15  \n",
      "3        15  \n",
      "4        16  \n",
      "      image                                               data  level  \\\n",
      "0   13_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "1  13_right  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "2   25_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "3  25_right  [[[0.00392156862745098, 0.00392156862745098, 0...      0   \n",
      "4   47_left  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0   \n",
      "\n",
      "  PatientID  \n",
      "0        13  \n",
      "1        13  \n",
      "2        25  \n",
      "3        25  \n",
      "4        47  \n"
     ]
    }
   ],
   "source": [
    "print(traindf.head())\n",
    "print(valSet.head())\n",
    "\n",
    "traindf = traindf.reset_index(drop=True)\n",
    "valSet = valSet.reset_index(drop=True)\n",
    "\n",
    "print(traindf.head())\n",
    "print(valSet.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape= 254 valX shape= 46\n"
     ]
    }
   ],
   "source": [
    "trainX = traindf['data']\n",
    "trainY = traindf['level']\n",
    "\n",
    "valX = valSet['data']\n",
    "valY = valSet['level']\n",
    "\n",
    "#(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.25, random_state=10)\n",
    "print('trainX shape=', trainX.shape[0], 'valX shape=', valX.shape[0]) # 750, 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY =  to_categorical(trainY, num_classes=NUM_CLASSES)\n",
    "valY =  to_categorical(valY, num_classes=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating images...\")\n",
    "sys.stdout.flush()\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=inputShape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    #onru\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    #irandu\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    #moonru\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim=NUM_CLASSES, activation='softmax'))\n",
    "    # naangu \n",
    "    #five classes so lastt layer willll be with 5 nodes\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping trainX at...2019-03-21 09:29:53.767500\n",
      "<class 'pandas.core.series.Series'>\n",
      "(254,)\n",
      "(254, 128, 128, 3)\n",
      "Reshaped trainX at...2019-03-21 09:29:53.840742\n"
     ]
    }
   ],
   "source": [
    "print(\"Reshaping trainX at...\"+ str(datetime.now()))\n",
    "#print(trainX.sample()) \n",
    "print(type(trainX)) # <class 'pandas.core.series.Series'>\n",
    "print(trainX.shape) # (750,)\n",
    "from numpy import zeros\n",
    "Xtrain = np.zeros([trainX.shape[0],HEIGHT, WIDTH, DEPTH])\n",
    "for i in range(trainX.shape[0]): # 0 to traindf Size -1\n",
    "    Xtrain[i] = trainX[i]\n",
    "print(Xtrain.shape) # (750,128,128,3)\n",
    "print(\"Reshaped trainX at...\"+ str(datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping valX at...2019-03-21 09:29:53.847744\n",
      "<class 'pandas.core.series.Series'>\n",
      "(46,)\n",
      "(46, 128, 128, 3)\n",
      "Reshaped valX at...2019-03-21 09:29:53.857526\n"
     ]
    }
   ],
   "source": [
    "print(\"Reshaping valX at...\"+ str(datetime.now()))\n",
    "print(type(valX)) # <class 'pandas.core.series.Series'>\n",
    "print(valX.shape) # (250,)\n",
    "from numpy import zeros\n",
    "Xval = np.zeros([valX.shape[0],HEIGHT, WIDTH, DEPTH])\n",
    "for i in range(valX.shape[0]): # 0 to traindf Size -1\n",
    "    Xval[i] = valX[i]\n",
    "print(Xval.shape) # (250,128,128,3)\n",
    "print(\"Reshaped valX at...\"+ str(datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,565,029\n",
      "Trainable params: 6,565,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aruve/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5)`\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"compiling model...\")\n",
    "sys.stdout.flush()\n",
    "model = createModel()\n",
    "\n",
    "# print the summary of model\n",
    "from keras.utils import print_summary\n",
    "print_summary(model, line_length=None, positions=None, print_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training network...\n",
      "Epoch 1/6\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"training network...\")\n",
    "sys.stdout.flush()\n",
    "#class_mode ='categorical', # 2D one-hot encoded labels\n",
    "H = model.fit_generator(aug.flow(Xtrain,trainY, ), \\\n",
    "    validation_data=(Xval, valY), \\\n",
    "    steps_per_epoch=len(trainX) // BS, \\\n",
    "    epochs=6, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"Saving model to disk\")\n",
    "sys.stdout.flush()\n",
    "model.save(\"retimodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating plots...\")\n",
    "sys.stdout.flush()\n",
    "matplotlib.use(\"Agg\")\n",
    "matplotlib.pyplot.style.use(\"ggplot\")\n",
    "matplotlib.pyplot.figure()\n",
    "N = EPOCHS\n",
    "matplotlib.pyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "matplotlib.pyplot.title(\"Training Loss and Accuracy on diabetic retinopathy detection\")\n",
    "matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "matplotlib.pyplot.ylabel(\"Loss/Accuracy\")\n",
    "matplotlib.pyplot.legend(loc=\"lower left\")\n",
    "matplotlib.pyplot.savefig(\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# coding=utf-8\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Flask utils\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/aruve/retimodel'\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"/home/aruve/train/54_right.jpeg\", target_size=(128, 128))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "x1 = np.expand_dims(x, axis=0)\n",
    "   \n",
    "\n",
    "import cv2\n",
    "\n",
    "preds = model.predict(Xtrain)\n",
    "print(np.argmax(preds,axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = model.predict(Xtrain)\n",
    "# sorting the predictions in descending order\n",
    "sorting = (-prediction1).argsort()\n",
    "\n",
    "# getting the top 2 predictions\n",
    "sorted_ = sorting[0][:2]\n",
    "\n",
    "for value in sorted_:\n",
    "    # you can get your classes from the encoder(your_classes = encoder.classes_) \n",
    "    # or from a dictionary that you created before.\n",
    "    # And then we access them with the predicted index.\n",
    "    predicted_label = trainY[value]\n",
    "\n",
    "    # just some rounding steps\n",
    "    prob = (prediction1[0][value]) * 100\n",
    "    prob = \"%.2f\" % round(prob,2)\n",
    "    print(\"I have %s%% sure that it belongs to %s.\" % (prob, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.unique(trainY, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training network...\")\n",
    "sys.stdout.flush()\n",
    "#class_mode ='categorical', # 2D one-hot encoded labels\n",
    "H = model.fit(Xtrain,trainY,validation_data=(Xval, valY),epochs=6, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"Saving model to disk\")\n",
    "sys.stdout.flush()\n",
    "model.save(\"ret1model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/aruve/retimodel'\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"/home/aruve/train/54_right.jpeg\", target_size=(128, 128))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "x1 = np.expand_dims(x, axis=0)\n",
    "   \n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "preds = model.predict_classes((Xtrain))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(valY,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
